{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://akhavanpour.ir/notebook/images/srttu.gif\" alt=\"SRTTU\" style=\"width: 150px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<li><a href=\"#ref1\">Data Acquisition</a>\n",
    "<li><a href=\"#ref2\">Basic Insight of Dataset</a></li>\n",
    "<p></p>\n",
    "Estimated Time Needed: <strong>10 min</strong>\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref1\"></a>\n",
    "# Data Acquisition\n",
    "There are various formats for a dataset, .csv, .json, .xlsx  etc. The dataset can be stored in different places, on your local machine or sometimes online.\n",
    "In this section, you will learn how to load a dataset into our Jupyter Notebook.\n",
    "In our case, the Automobile Dataset is an online source, and it is in CSV (comma separated value) format. Let's use this dataset as an example to practice data reading.\n",
    "data source: https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\n",
    "data type: csv\n",
    "The Pandas Library is a useful tool that enables us to read various datasets into a data frame; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n",
    "We use **\"pandas.read_csv()\"**  function to read the csv file. In the bracket, we put the file path along with a quotation mark, so that pandas will read the file into a data frame from that address. The file path can be either an URL or your local file address.\n",
    "Because the data does not include headers, we can add an argument **\" headers = None\"**  inside the  **\"read_csv()\"** method, so that pandas will not automatically set the first row as a header.\n",
    "You can also assign the dataset to any variable you create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pandas library\n",
    "import pandas as pd\n",
    "# read the online file by the URL provides above, and assign it to variable \"df\"\n",
    "path=\"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
    "\n",
    "df = pd.read_csv(path,header=None)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading the dataset, we can use the **`dataframe.head(n)`** method to check the top n rows of the dataframe; where n is an integer. Contrary to **`dataframe.head(n)`**, **`dataframe.tail(n)`** will show you the bottom n rows of the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show the first 5 rows using dataframe.head() method\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "<h1> Question #1: </h1>\n",
    "<b>check the bottom 10 rows of data frame \"df\".</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "<h1> Question #1 Answer: </h1>\n",
    "<b>Run the code below! Did you get the right code?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click __here__ for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "df.tail(10)\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Headers\n",
    "Take a look at our dataset; pandas automatically set the header by an integer from 0. \n",
    "<div>\n",
    "To better describe our data we can introduce a header, this information is available at:  https://archive.ics.uci.edu/ml/datasets/Automobile</div>\n",
    "<p></p>\n",
    "<div>Thus, we have to add headers manually.</div>\n",
    "<div>Firstly, we create a list \"headers\" that include all column names in order.</div>\n",
    "<div>Then, we use **`dataframe.columns = headers`** to replace the headers by the list we created.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create headers list\n",
    "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
    "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
    "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
    "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]\n",
    "headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We replace headers and recheck our data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns = headers\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can drop missing values along the column \"price\" as follows  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"price\"], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have successfully read the raw dataset and add the correct headers into the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "<h1> Question #2: </h1>\n",
    "<b>Find the name of the colunms of the dataframe</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click __here__ for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "df.columns\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dataset\n",
    "Correspondingly, Pandas enables us to save the dataset to csv  by using the **`dataframe.to_csv()`** method, you can add the file path and name along with quotation marks in the brackets.\n",
    "\n",
    "For example, if you would save the dataframe \"df\" as \"automobile.csv\" to your local machine, you may use the syntax below:\n",
    "~~~~\n",
    "df.to_csv(\"automobile.csv\")\n",
    "~~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can also read and save other file formats, we can use similar functions to **`pd.read_csv()`** and **`df.to_csv()`** for other data formats, the functions are listed in the following table:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read/Save Other Data Formats\n",
    "\n",
    "\n",
    "\n",
    "| Data Formate  | Read           | Save             |\n",
    "| ------------- |:--------------:| ----------------:|\n",
    "| csv           | `pd.read_csv()`  |`df.to_csv()`     |\n",
    "| json          | `pd.read_json()` |`df.to_json()`    |\n",
    "| excel         | `pd.read_excel()`|`df.to_excel()`   |\n",
    "| hdf           | `pd.read_hdf()`  |`df.to_hdf()`     |\n",
    "| sql           | `pd.read_sql()`  |`df.to_sql()`     |\n",
    "| ...           |   ...          |       ...        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref2\"></a>\n",
    "# Basic Insight of Dataset\n",
    "After reading data into Pandas dataframe, it is time for us to explore the dataset.\n",
    "There are several ways to obtain essential insights of the data to help us better understand our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types\n",
    "Data has a variety of types.\n",
    "The main types stored in Pandas dataframes are `object`, `float`, `int`, `bool` and `datetime64`. In order to better learn about each attribute, it is always good for us to know the data type of each column. In Pandas:\n",
    "~~~~\n",
    "dataframe.dtypes\n",
    "~~~~\n",
    "returns a Series with the data type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check the data type of data frame \"df\" by .dtypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, as shown above, it is clear to see that the data type of \"symboling\" and \"curb-weight\" are `int64`, \"normalized-losses\" is `object`, and \"wheel-base\" is `float64`, etc.\n",
    "These data types can be changed; we will learn how to accomplish this in a later module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe\n",
    "If we would like to get a statistical summary of each column, such as  count, column mean value, column standard deviation, etc. We use the describe method:\n",
    "~~~~\n",
    "dataframe.describe()\n",
    "~~~~\n",
    "This method will provide various summary statistics, excluding `NaN` (Not a Number) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the statistical summary of all numeric-typed (int, float) columns.\n",
    "For example, the attribute \"symboling\" has 205 counts, the mean value of this column is 0.83, the standard deviation is 1.25, the minimum value is -2, 25th percentile is 0, 50th percentile is 1, 75th percentile is 2, and the maximum value is 3.\n",
    "\n",
    "However, what if we would also like to check all the columns including those that are of type object.\n",
    "\n",
    "\n",
    "You can add an argument `include = \"all\"` inside the bracket. Let's try it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# describe all the columns in \"df\" \n",
    "df.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it provides the statistical summary of all the columns, including object-typed attributes.\n",
    "We can now see how many unique values, which is the top value and the frequency of top value in the object-typed columns.\n",
    "Some values in the table above show as \"NaN\", this is because those numbers are not available regarding a particular column type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "<h1> Question #3: </h1>\n",
    "\n",
    "<p>You can select the columns of a data frame by indicating the name of  each column, for example, you can select the three columns as follows:</p>\n",
    "<p></p>\n",
    "<p>dataframe[[' column 1 ',column 2', 'column 3'] ]</p>\n",
    "<p></p>\n",
    "<p>where \"column\" is the name of the column, you can apply the method  \".describe()\" to get the statistics of those columns as follows:</p>\n",
    "<p></p>\n",
    "<p>dataframe[[' column 1 ',column 2', 'column 3'] ].describe() </p>\n",
    "<p></p>\n",
    "\n",
    "Apply the  method to \".describe()\" to the columns 'length' and 'compression-ratio'.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click __here__ for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "df[['length','compression-ratio']].describe()\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info\n",
    "Another method you can use to check your dataset is:\n",
    "~~~~\n",
    "dataframe.info\n",
    "~~~~\n",
    "It provide a concise summary of your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at the info of \"df\"\n",
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are able to see the information of our dataframe, with the top 30 rows and the bottom 30 rows.\n",
    "\n",
    "And, it also shows us the whole data frame has 205 rows and 26 columns in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excellent! You have just completed the  Introduction  Notebook! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "### About the Authors:  \n",
    "\n",
    "This notebook was written by [Mahdi Noorian PhD](https://www.linkedin.com/in/mahdi-noorian-58219234/) ,[Joseph Santarcangelo PhD]( https://www.linkedin.com/in/joseph-s-50398b136/), Bahare Talayian, Eric Xiao, Steven Dong, Parizad , Hima Vsudevan and [Fiorella Wenver](https://www.linkedin.com/in/fiorellawever/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Copyright &copy; 2017 [cognitiveclass.ai](cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
